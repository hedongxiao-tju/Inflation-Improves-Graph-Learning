{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inflations Improve GL",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3Tzp_5lnqzK"
      },
      "outputs": [],
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_seed(seed, cuda):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if cuda is True:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "setup_seed(123, torch.cuda.is_available())\n",
        "random.seed(123)"
      ],
      "metadata": {
        "id": "c4eDT0bEnzuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv, ChebConv  # noqa\n",
        "\n",
        "dataset = 'Pubmed'\n",
        "path = osp.join('', dataset)\n",
        "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "aNugwQlioBqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_features, dim, cached=True,\n",
        "                             normalize= 1)\n",
        "        self.conv0 = GCNConv(dim, dataset.num_classes, cached=True,\n",
        "                             normalize= 1)\n",
        "        self.keep = nn.Softmax()\n",
        "\n",
        "    def forward(self):\n",
        "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n",
        "        x = self.inflation(self.keep(self.conv1(x, edge_index, edge_weight)), config['power'])\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = self.conv0(x, edge_index, edge_weight)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def inflation(self, x, pow):\n",
        "\n",
        "        power = pow\n",
        "        x = x / x.sum(-1).unsqueeze(-1).expand_as(x)\n",
        "        x = x.pow(power)\n",
        "        x = x / x.sum(-1).unsqueeze(-1).expand_as(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "rJT1QP6UoJ9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam([\n",
        "    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
        "    dict(params=model.conv0.parameters(), weight_decay=0)\n",
        "], lr=0.05)  # Only perform weight-decay on first convolution.\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "    optimizer.step()\n",
        "    a = F.nll_loss(model()[data.train_mask], data.y[data.train_mask])\n",
        "    return a\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    logits, accs = model(), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "best_val_acc = test_acc = 0\n",
        "for epoch in range(1, 1501):\n",
        "    a = train()\n",
        "    train_acc, val_acc, tmp_test_acc = test()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        test_acc = tmp_test_acc\n",
        "    if epoch % 5 == 0:\n",
        "      log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {:.4f}'\n",
        "      print(log.format(epoch, train_acc, best_val_acc, test_acc, a))"
      ],
      "metadata": {
        "id": "YuNtgUzdougC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'seed': 123456,\n",
        "    'power': 2\n",
        "}"
      ],
      "metadata": {
        "id": "z7z8vnYLqjBD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}